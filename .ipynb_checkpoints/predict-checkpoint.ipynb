{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85132297-2a39-44de-9758-0bd0dfdd10b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b3b0183-b468-4144-bc8e-a6e7681baffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_dropout_predictions_class(model, inputs, label_encoder, n_samples=100):\n",
    "    predictions = []\n",
    "    for _ in range(n_samples):\n",
    "        pred_output = model(inputs, training=True)  # Dropout active during inference\n",
    "        pred_output = pred_output.numpy().argmax(1)\n",
    "        pred_classes = label_encoder.inverse_transform(pred_output)  # Decode predicted classes\n",
    "        predictions.append(pred_classes)\n",
    "        \n",
    "    predictions = np.stack(predictions)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b6c8768-1c10-41f1-9e51-0f7e4b3d87b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model_dl = load_model('trained_model.h5')\n",
    "le = joblib.load('label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c43d1af9-d5dd-4683-980b-fd097df3755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "#Import all csv file under Train_data folder\n",
    "############################################\n",
    "\n",
    "folder_path = \"Predict_data\"\n",
    "# List to hold DataFrames\n",
    "dataframes = []\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        dataframes.append(df)\n",
    "\n",
    "combined_data = pd.concat(dataframes, ignore_index=True)\n",
    "combined_data.to_csv('combined_predict_data.csv', index=False)\n",
    "file_path = os.path.join('combined_predict_data.csv')\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "535ed079-40db-41e6-854b-68c220d8c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seqs = np.array([test_item.replace(\"|\", \",\").replace(\",\", \" \") for test_item in data[\"sequence\"].values])\n",
    "test_seqs2 = test_seqs[0:100]\n",
    "test_seqs2.shape\n",
    "label = data['cgc_id'][0:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b45033ac-505f-4518-846c-2d6c45aec9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = mc_dropout_predictions_class(model_dl, test_seqs2, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb7bb38b-6af7-4db3-8388-3ebd85a89a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_result = result.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e5400cd-d063-401a-8f29-ffead839f81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['starch', 'starch', 'starch', ..., 'starch', 'starch', 'starch'],\n",
       "       ['host glycan', 'host glycan', 'pectin', ..., 'pectin', 'pectin',\n",
       "        'pectin'],\n",
       "       ['pectin', 'pectin', 'pectin', ..., 'pectin', 'pectin', 'pectin'],\n",
       "       ...,\n",
       "       ['starch', 'pectin', 'pectin', ..., 'xylan', 'xylan', 'pectin'],\n",
       "       ['pectin', 'pectin', 'pectin', ..., 'pectin', 'pectin', 'pectin'],\n",
       "       ['pectin', 'pectin', 'pectin', ..., 'pectin', 'pectin', 'pectin']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5829984a-b52a-48f4-891a-b04330c93581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['alginate', 'beta-glucan', 'cellulose', 'host glycan', 'pectin',\n",
       "       'starch', 'xylan'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_numbers = np.unique(t_result)  # Get the unique numbers in the array\n",
    "unique_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f141bf28-efdd-46f9-ba33-2ef457b58d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   2  98   0]\n",
      " [  3   0   0  34  61   1   1]\n",
      " [  0   0   0   1  99   0   0]\n",
      " [  3   1   0  89   7   0   0]\n",
      " [  0   0   1   0  73   0  26]\n",
      " [  0   0   3   0  30   0  67]\n",
      " [  0   0  88   0   2   2   8]\n",
      " [  0   3   1  26  70   0   0]\n",
      " [ 34   0   0   2  64   0   0]\n",
      " [  0   0   4   0  95   0   1]\n",
      " [  0   0   0   0  99   0   1]\n",
      " [  0   0   0   0  98   0   2]\n",
      " [  0   0   0   6  93   0   1]\n",
      " [  1   0   1   0  98   0   0]\n",
      " [  2  87   0   2   9   0   0]\n",
      " [  0   0   0  25  75   0   0]\n",
      " [  0   0   0   0  52   0  48]\n",
      " [  0   0   0   0  82   7  11]\n",
      " [  0   0   9  14  65  12   0]\n",
      " [  0   0   0   0 100   0   0]\n",
      " [  3   0   0   0  73   1  23]\n",
      " [  0   0   0  39  61   0   0]\n",
      " [  3   0   0   2  94   0   1]\n",
      " [  0   0   0   0  11   0  89]\n",
      " [  0  41   2  40  13   0   4]\n",
      " [  0   0   7   0  43   0  50]\n",
      " [  0   5  72   6  17   0   0]\n",
      " [  0   0   0   0  27  71   2]\n",
      " [  0   0   0   0  80   0  20]\n",
      " [  0   0   0   0  92   0   8]\n",
      " [  0   0   0   1  99   0   0]\n",
      " [  2   0   0  47  39   9   3]\n",
      " [  1   0   0   0  37   0  62]\n",
      " [  0   0   1   8  91   0   0]\n",
      " [ 16   0   0   1  83   0   0]\n",
      " [  0   0   1  43  56   0   0]\n",
      " [  0   0   7   4  73   4  12]\n",
      " [  0   0   3   0   0   0  97]\n",
      " [  0   0   0   0   4   0  96]\n",
      " [  1   0   1  15  82   0   1]\n",
      " [  0   0   1  12  86   1   0]\n",
      " [  0   0  47   0  51   1   1]\n",
      " [  0   0   0  16  84   0   0]\n",
      " [  0   0   0  13  83   1   3]\n",
      " [  4   0   0   0  57   0  39]\n",
      " [  0   0   0   0  96   0   4]\n",
      " [  0   0   0  99   1   0   0]\n",
      " [ 10   0   0   0  88   0   2]\n",
      " [  0   0   2   5  84   2   7]\n",
      " [  0   0   1  20  70   7   2]\n",
      " [ 36  10   2   7  45   0   0]\n",
      " [  4   0   0   6  90   0   0]\n",
      " [ 11   1   0   4  74  10   0]\n",
      " [  0   0   6  13  65  11   5]\n",
      " [  0   0   0   4  79  17   0]\n",
      " [  2   0   0   4  91   0   3]\n",
      " [  1   0   0   0  95   0   4]\n",
      " [  7   0   2   4  79   0   8]\n",
      " [  0   0   3  16  80   1   0]\n",
      " [  0   0   0   1  98   0   1]\n",
      " [ 12   0   0   5  83   0   0]\n",
      " [  0   0   0   0   3  97   0]\n",
      " [  0   0   2  15  43  40   0]\n",
      " [  4   0   0   2  78  16   0]\n",
      " [  0   0   0  14  84   1   1]\n",
      " [  0   0   1  96   3   0   0]\n",
      " [  1   0   0  18  80   0   1]\n",
      " [  0   0   0   9  40  51   0]\n",
      " [  8  64   0   0  17   0  11]\n",
      " [  1   0   0  26  73   0   0]\n",
      " [  3   0   0   2  94   0   1]\n",
      " [  0   0   0  17  22  59   2]\n",
      " [  0  33   0  57   1   9   0]\n",
      " [  0   0   0  16  83   0   1]\n",
      " [  0   0   0  24  18  58   0]\n",
      " [ 14   0   0   0  82   0   4]\n",
      " [  0   0   0   1  99   0   0]\n",
      " [  0   0   0  28  33  39   0]\n",
      " [  3   0   0   0  95   2   0]\n",
      " [  9   0   0   0  91   0   0]\n",
      " [  0   0   0   0   3   0  97]\n",
      " [  0   0   2   3  92   0   3]\n",
      " [  0   1  18   0  79   0   2]\n",
      " [ 14   0   0  17  69   0   0]\n",
      " [  7   0   1  11  74   7   0]\n",
      " [  9  10   0   1  80   0   0]\n",
      " [  5  81   0   5   9   0   0]\n",
      " [  0   1  20  18  55   1   5]\n",
      " [  0   0  14   5  39  20  22]\n",
      " [  3   0   0   3  92   0   2]\n",
      " [ 50   0   1  31  17   0   1]\n",
      " [  3   0   0   3  94   0   0]\n",
      " [  0   0   0   2  95   0   3]\n",
      " [  0   0   0  27  61  12   0]\n",
      " [  0   0   0   1  99   0   0]\n",
      " [  0   1   0   0  99   0   0]\n",
      " [  0   0   2  50  48   0   0]\n",
      " [  0   0   1   7  77   1  14]\n",
      " [  0   0   0  10  90   0   0]\n",
      " [  1   0   0   2  96   1   0]]\n"
     ]
    }
   ],
   "source": [
    "unique_numbers = np.unique(t_result)  # Get the unique numbers in the array\n",
    "\n",
    "# Initialize an empty array to store the counts\n",
    "counts_by_row = np.zeros((t_result.shape[0], len(unique_numbers)), dtype=int)\n",
    "\n",
    "# Iterate over each row and count the occurrences of each unique number\n",
    "for i, row in enumerate(t_result):\n",
    "    counts = np.array([np.sum(row == num) for num in unique_numbers])\n",
    "    counts_by_row[i] = counts\n",
    "\n",
    "# Print the counts\n",
    "print(counts_by_row)\n",
    "result = pd.DataFrame(counts_by_row, columns = unique_numbers)\n",
    "result.insert(0, 'ID', label)\n",
    "result.to_csv('predictions_counts.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DKL",
   "language": "python",
   "name": "dkl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
